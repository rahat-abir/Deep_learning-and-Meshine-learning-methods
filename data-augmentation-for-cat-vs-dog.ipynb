{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1003830,"sourceType":"datasetVersion","datasetId":550917}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-05-17T19:34:10.245369Z","iopub.execute_input":"2024-05-17T19:34:10.245877Z","iopub.status.idle":"2024-05-17T19:34:10.254530Z","shell.execute_reply.started":"2024-05-17T19:34:10.245839Z","shell.execute_reply":"2024-05-17T19:34:10.253255Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"batch_size = 16","metadata":{"execution":{"iopub.status.busy":"2024-05-17T19:34:11.264782Z","iopub.execute_input":"2024-05-17T19:34:11.265825Z","iopub.status.idle":"2024-05-17T19:34:11.269812Z","shell.execute_reply.started":"2024-05-17T19:34:11.265779Z","shell.execute_reply":"2024-05-17T19:34:11.269019Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# remember to **train-test-split** if only train data is given.","metadata":{}},{"cell_type":"code","source":"#remember to train test split if only train data is given.\n\n#augmentation parameters for train data\ntrain_datagen = ImageDataGenerator(\n    rescale = 1./255,          #multiply the data before any other processing\n    shear_range = 0.2,         #another type of changing the image\n    zoom_range = 0.2,          #zooming at different points\n    horizontal_flip = True      #all the images will be horizontal, there are also vertical flip but we wont use them on objects that needs to be up right.\n    \n    \n    #rotation_range=40,          randomly rotate pictures\n    #width_shift_range=0.2,        translate pictures vertically or horizontally\n    #height_shift_range=0.2,        multiply the data before any other processing\n    #fill_mode='nearest'           filling in newly created pixels\n)\n\n\n#augmentation parameters for test data\ntest_datagen = ImageDataGenerator(rescale =1./255)\\\n#only rescale coz we dont need extra augmentation in traning\n\n\n#applying the augmentation in tarin data\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages',   #target directory          \n    target_size = (150,150),                                  #target_size\n    batch_size = batch_size,\n    class_mode = 'binary'                                     #class mode \"binary\" - for binary classification\n                                                               #\"categorical\" - for categorical classification\n                                                               #\"sparse\" - for sparse categorical classification\n                                                               #\"input\" - for input data only, no labels\n)\n\n\n#applying the augmentation in validation data\nvalidation_generator= test_datagen.flow_from_directory(\n    '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages',          \n    target_size = (150,150),                      #all same as train generator            \n    batch_size = batch_size,\n    class_mode = 'binary'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T19:34:13.038863Z","iopub.execute_input":"2024-05-17T19:34:13.040022Z","iopub.status.idle":"2024-05-17T19:34:35.916093Z","shell.execute_reply.started":"2024-05-17T19:34:13.039979Z","shell.execute_reply":"2024-05-17T19:34:35.914850Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Found 25000 images belonging to 2 classes.\nFound 25000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Appling a model on the augmented data","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense","metadata":{"execution":{"iopub.status.busy":"2024-05-17T19:34:43.347201Z","iopub.execute_input":"2024-05-17T19:34:43.347674Z","iopub.status.idle":"2024-05-17T19:34:43.352941Z","shell.execute_reply.started":"2024-05-17T19:34:43.347635Z","shell.execute_reply":"2024-05-17T19:34:43.351947Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = Sequential()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T19:34:49.695333Z","iopub.execute_input":"2024-05-17T19:34:49.695815Z","iopub.status.idle":"2024-05-17T19:34:49.702596Z","shell.execute_reply.started":"2024-05-17T19:34:49.695777Z","shell.execute_reply":"2024-05-17T19:34:49.701507Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.add(Conv2D(32, (3,3), input_shape = (150,150,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(32, (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(64, (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T19:35:01.404854Z","iopub.execute_input":"2024-05-17T19:35:01.405611Z","iopub.status.idle":"2024-05-17T19:35:01.497983Z","shell.execute_reply.started":"2024-05-17T19:35:01.405570Z","shell.execute_reply":"2024-05-17T19:35:01.496559Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"}]},{"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T19:35:03.465140Z","iopub.execute_input":"2024-05-17T19:35:03.465585Z","iopub.status.idle":"2024-05-17T19:35:03.563261Z","shell.execute_reply.started":"2024-05-17T19:35:03.465552Z","shell.execute_reply":"2024-05-17T19:35:03.561783Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-17T19:35:04.684833Z","iopub.execute_input":"2024-05-17T19:35:04.685657Z","iopub.status.idle":"2024-05-17T19:35:04.696506Z","shell.execute_reply.started":"2024-05-17T19:35:04.685617Z","shell.execute_reply":"2024-05-17T19:35:04.695372Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    train_generator,\n    validation_data = validation_generator,\n    epochs=10\n)\n\n","metadata":{},"execution_count":null,"outputs":[]}]}