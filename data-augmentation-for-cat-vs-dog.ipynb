{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1003830,"sourceType":"datasetVersion","datasetId":550917}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:41:15.029264Z","iopub.execute_input":"2024-05-17T17:41:15.029636Z","iopub.status.idle":"2024-05-17T17:41:15.036052Z","shell.execute_reply.started":"2024-05-17T17:41:15.029611Z","shell.execute_reply":"2024-05-17T17:41:15.034921Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"batch_size = 16","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:41:35.468840Z","iopub.execute_input":"2024-05-17T17:41:35.469218Z","iopub.status.idle":"2024-05-17T17:41:35.473588Z","shell.execute_reply.started":"2024-05-17T17:41:35.469193Z","shell.execute_reply":"2024-05-17T17:41:35.472786Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# remember to **train-test-split** if only train data is given.","metadata":{}},{"cell_type":"code","source":"#remember to train test split if only train data is given.\n\n#augmentation parameters for train data\ntrain_datagen = ImageDataGenerator(\n    rescale = 1./255,          #multiply the data before any other processing\n    shear_range = 0.2,         #another type of changing the image\n    zoom_range = 0.2,          #zooming at different points\n    horizontal_flip = True      #all the images will be horizontal, there are also vertical flip but we wont use them on objects that needs to be up right.\n    \n    \n    #rotation_range=40,          randomly rotate pictures\n    #width_shift_range=0.2,        translate pictures vertically or horizontally\n    #height_shift_range=0.2,        multiply the data before any other processing\n    #fill_mode='nearest'           filling in newly created pixels\n)\n\n\n#augmentation parameters for test data\ntest_datagen = ImageDataGenerator(rescale =1./255)\\\n#only rescale coz we dont need extra augmentation in traning\n\n\n#applying the augmentation in tarin data\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages',   #target directory          \n    target_size = (150,150),                                  #target_size\n    batch_size = batch_size,\n    class_mode = 'binary'                                     #class mode \"binary\" - for binary classification\n                                                               #\"categorical\" - for categorical classification\n                                                               #\"sparse\" - for sparse categorical classification\n                                                               #\"input\" - for input data only, no labels\n)\n\n\n#applying the augmentation in validation data\nvalidation_generator= test_datagen.flow_from_directory(\n    '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages',          \n    target_size = (150,150),                      #all same as train generator            \n    batch_size = batch_size,\n    class_mode = 'binary'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:56:38.736575Z","iopub.execute_input":"2024-05-17T17:56:38.736985Z","iopub.status.idle":"2024-05-17T17:56:50.322426Z","shell.execute_reply.started":"2024-05-17T17:56:38.736942Z","shell.execute_reply":"2024-05-17T17:56:50.321325Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Found 25000 images belonging to 2 classes.\nFound 25000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:58:36.754812Z","iopub.execute_input":"2024-05-17T17:58:36.757290Z","iopub.status.idle":"2024-05-17T17:58:36.789153Z","shell.execute_reply.started":"2024-05-17T17:58:36.757245Z","shell.execute_reply":"2024-05-17T17:58:36.788033Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n","\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'DirectoryIterator' object has no attribute 'shape'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}